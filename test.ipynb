{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43859993d48bf350",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "training_paths = ['data/raw/character_set1/training_data/',\n",
    "                 'data/raw/character_set3/', ]\n",
    "#testing_path = 'data/raw/character_set1/testing_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc146db7c198a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_path in training_paths:\n",
    "    dir_list = os.listdir(training_path)\n",
    "    for i in dir_list:\n",
    "        print(f\"Processing label: {i}\")  # Add this line to check labels\n",
    "        dir = os.path.join(training_path, i)\n",
    "        file_list = os.listdir(dir)\n",
    "        for j in file_list:\n",
    "            files = os.path.join(dir, j)\n",
    "            img = cv2.imread(files, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Unable to read image {files}. Skipping.\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "            img = img.astype('float32') / 255.0\n",
    "            images.append(img)\n",
    "            labels.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e963705255a7dd",
   "metadata": {},
   "source": [
    "## Print out details of X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f793a21829d226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "print(\"len(X): \",len(X))\n",
    "print(\"X.shape: \", X.shape)\n",
    "\n",
    "y = np.array(labels)\n",
    "print(\"len(y): \",len(y))\n",
    "print(\"y.shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd15726c2948ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(\"Classes:\", le.classes_)\n",
    "X_sh, y_sh = shuffle(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836a9999f9df7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sh, y_sh, test_size=0.2, random_state=42, stratify=y_sh\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Testing samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09ffaf114d8e14",
   "metadata": {},
   "source": [
    "# Create Keras model\n",
    "create a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a831ac19fad1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(64,64,1)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=len(le.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e867168d5fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ebe91b9921e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Fit the data generator\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Use the generator in model training\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=25),\n",
    "                    validation_data=(X_test, y_test), epochs=20)\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314eb075e9928a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Separate Evaluation for Uppercase and Lowercase Characters\n",
    "\n",
    "# Determine the number of uppercase letters\n",
    "# This assumes that the first 'num_uppercase' classes are uppercase letters\n",
    "# Adjust 'num_uppercase' based on your actual label encoding\n",
    "num_uppercase = 26  # Typically, A-Z\n",
    "\n",
    "# Find indices for uppercase and lowercase characters\n",
    "uppercase_indices = np.where(y_test < num_uppercase)\n",
    "lowercase_indices = np.where(y_test >= num_uppercase)\n",
    "\n",
    "# Evaluate the model on uppercase characters\n",
    "test_loss_upper, test_acc_upper = model.evaluate(X_test[uppercase_indices], y_test[uppercase_indices], verbose=0)\n",
    "print(f\"Uppercase Test Loss: {test_loss_upper:.4f}\")\n",
    "print(f\"Uppercase Test Accuracy: {test_acc_upper:.4f}\")\n",
    "\n",
    "# Evaluate the model on lowercase characters\n",
    "test_loss_lower, test_acc_lower = model.evaluate(X_test[lowercase_indices], y_test[lowercase_indices], verbose=0)\n",
    "print(f\"Lowercase Test Loss: {test_loss_lower:.4f}\")\n",
    "print(f\"Lowercase Test Accuracy: {test_acc_lower:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7cd2e62b3b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35364e",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb07506",
   "metadata": {},
   "source": [
    "### Visualize Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_regions(image, regions):\n",
    "    debug_image = image.copy()\n",
    "    for (x, y, w, h) in regions:\n",
    "        cv2.rectangle(debug_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Detected Text Regions\", debug_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914107cc",
   "metadata": {},
   "source": [
    "### Visualize Processed Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34884b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_processed_image(window_name, processed_image):\n",
    "    cv2.imshow(window_name, processed_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915dce9",
   "metadata": {},
   "source": [
    "## Image Processing Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330375c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing_operations_visualization(image, operation):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if operation == 'threshold':\n",
    "        # Apply thresholding to get a binary image\n",
    "        _, processed_image = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "        window_name = \"Thresholded Image\"\n",
    "\n",
    "    elif operation == 'erosion':\n",
    "        # Apply thresholding and then erosion\n",
    "        _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "        kernel = np.ones((2, 1), np.uint8)\n",
    "        processed_image = cv2.erode(thresh, kernel, iterations=1)\n",
    "        window_name = \"Eroded Image\"\n",
    "\n",
    "    elif operation == 'dilation':\n",
    "        # Apply thresholding and then dilation\n",
    "        _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        processed_image = cv2.dilate(thresh, kernel, iterations=1)\n",
    "        window_name = \"Dilated Image\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Operation must be 'threshold', 'erosion', or 'dilation'\")\n",
    "\n",
    "    # Display the processed image\n",
    "    display_processed_image(window_name, processed_image)\n",
    "    \n",
    "    return _, processed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ff14b",
   "metadata": {},
   "source": [
    "## Italic Characters Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5020",
   "metadata": {},
   "source": [
    "### Compute Skew Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_skew_angle(region):\n",
    "    # Use moments to calculate the skew angle of a text region\n",
    "    coords = np.column_stack(np.where(region > 0))\n",
    "    rect = cv2.minAreaRect(coords)\n",
    "    angle = rect[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b0f10",
   "metadata": {},
   "source": [
    "### Deskew Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew_region(region, angle):\n",
    "    # Rotate the region by the computed angle\n",
    "    (h, w) = region.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(region, rotation_matrix, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=255)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad712c7e",
   "metadata": {},
   "source": [
    "## Detect Text Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_regions(image):\n",
    "    # Convert image to grayscale if it's not already\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Apply adaptive thresholding with adjusted parameters\n",
    "    processed_image = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV, 15, 10  # Increased block size and constant\n",
    "    )\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(\n",
    "        processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    regions = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Adjusted size thresholds\n",
    "        if w > 3 and h > 3:\n",
    "            regions.append((x, y, w, h))\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c378b3",
   "metadata": {},
   "source": [
    "## Sorting Bounding Boxes by Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8198074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_bounding_boxes(regions):\n",
    "    # Sort by `y` first (top-to-bottom) with a threshold to group by rows\n",
    "    row_threshold = 20  # Adjust based on character spacing\n",
    "    regions = sorted(regions, key=lambda box: box[1])\n",
    "\n",
    "    # Group bounding boxes into rows\n",
    "    rows = []\n",
    "    current_row = [regions[0]]\n",
    "    \n",
    "    for i in range(1, len(regions)):\n",
    "        if abs(regions[i][1] - current_row[-1][1]) < row_threshold:\n",
    "            current_row.append(regions[i])\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [regions[i]]\n",
    "    rows.append(current_row)\n",
    "    \n",
    "    # Sort each row left-to-right\n",
    "    sorted_regions = []\n",
    "    for row in rows:\n",
    "        sorted_row = sorted(row, key=lambda box: box[0])\n",
    "        sorted_regions.extend(sorted_row)\n",
    "    \n",
    "    return sorted_regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f0c99",
   "metadata": {},
   "source": [
    "## Resize Image Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64543a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, target_size=(64, 64)):\n",
    "    # Resize while maintaining aspect ratio and pad the image\n",
    "    (h, w) = image.shape[:2]\n",
    "    scaling_factor = min(target_size[0]/w, target_size[1]/h)\n",
    "    new_size = (int(w * scaling_factor), int(h * scaling_factor))\n",
    "    resized_image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Pad the resized image to make it target_size\n",
    "    delta_w = target_size[0] - new_size[0]\n",
    "    delta_h = target_size[1] - new_size[1]\n",
    "    top, bottom = delta_h//2, delta_h - (delta_h//2)\n",
    "    left, right = delta_w//2, delta_w - (delta_w//2)\n",
    "    padded_image = cv2.copyMakeBorder(\n",
    "        resized_image, top, bottom, left, right,\n",
    "        cv2.BORDER_CONSTANT, value=255\n",
    "    )\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d217243",
   "metadata": {},
   "source": [
    "## Recognize Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012cec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_characters(image, model, label_encoder):\n",
    "    regions = detect_text_regions(image)\n",
    "    sorted_regions = sort_bounding_boxes(regions)\n",
    "    characters = []\n",
    "    for (x, y, w, h) in sorted_regions:\n",
    "        char_image = image[y:y+h, x:x+w]\n",
    "        # Convert to grayscale if necessary\n",
    "        if len(char_image.shape) == 3:\n",
    "            char_image = cv2.cvtColor(char_image, cv2.COLOR_BGR2GRAY)\n",
    "        # Deskew the character image\n",
    "        angle = compute_skew_angle(char_image)\n",
    "        char_image = deskew_region(char_image, angle)\n",
    "        # Resize and normalize\n",
    "        char_image_resized = resize_image(char_image, (64, 64))\n",
    "        char_image_normalized = char_image_resized.astype('float32') / 255.0\n",
    "        # Expand dimensions to match input shape\n",
    "        char_image_normalized = np.expand_dims(char_image_normalized, axis=-1)\n",
    "        char_image_normalized = np.expand_dims(char_image_normalized, axis=0)\n",
    "        # Predict\n",
    "        prediction = model.predict(char_image_normalized)\n",
    "        predicted_class = np.argmax(prediction, axis=1)\n",
    "        predicted_char = label_encoder.inverse_transform(predicted_class)[0]\n",
    "        characters.append(predicted_char)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2d4fe",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imggg = 'data/raw/character_set1/Test_1.png'\n",
    "image = cv2.imread(imggg) \n",
    "y_pred = recognize_characters(image, model, le)\n",
    "print(y_pred)\n",
    "print(len(y_pred))\n",
    "print(''.join(y_pred))\n",
    "print('IntroductiontoAlgorithmsFourthEdition')\n",
    "\n",
    "\n",
    "# Load a single lowercase character image\n",
    "test_img = cv2.imread('data/raw/character_set3/a/A_L_1.png', cv2.IMREAD_GRAYSCALE)\n",
    "test_img_resized = cv2.resize(test_img, (64, 64)).astype('float32') / 255.0\n",
    "test_img_input = np.expand_dims(np.expand_dims(test_img_resized, axis=-1), axis=0)\n",
    "\n",
    "prediction = model.predict(test_img_input)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "predicted_char = le.inverse_transform(predicted_class)\n",
    "print(\"Predicted character:\", predicted_char)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
